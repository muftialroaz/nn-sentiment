{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import nltk\n",
    "import demoji\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import unicodedata as uni\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from nltk.corpus import stopwords \n",
    "from collections import Counter\n",
    "import string\n",
    "import re\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S No.</th>\n",
       "      <th>Title</th>\n",
       "      <th>Decisions</th>\n",
       "      <th>Words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>SpiceJet to issue 6.4 crore warrants to promoters</td>\n",
       "      <td>{\"SpiceJet\": \"neutral\"}</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>MMTC Q2 net loss at Rs 10.4 crore</td>\n",
       "      <td>{\"MMTC\": \"neutral\"}</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Mid-cap funds can deliver more, stay put: Experts</td>\n",
       "      <td>{\"Mid-cap funds\": \"positive\"}</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Mid caps now turn into market darlings</td>\n",
       "      <td>{\"Mid caps\": \"positive\"}</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Market seeing patience, if not conviction: Pra...</td>\n",
       "      <td>{\"Market\": \"neutral\"}</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   S No.                                              Title  \\\n",
       "0      1  SpiceJet to issue 6.4 crore warrants to promoters   \n",
       "1      2                  MMTC Q2 net loss at Rs 10.4 crore   \n",
       "2      3  Mid-cap funds can deliver more, stay put: Experts   \n",
       "3      4             Mid caps now turn into market darlings   \n",
       "4      5  Market seeing patience, if not conviction: Pra...   \n",
       "\n",
       "                       Decisions  Words  \n",
       "0        {\"SpiceJet\": \"neutral\"}      8  \n",
       "1            {\"MMTC\": \"neutral\"}      8  \n",
       "2  {\"Mid-cap funds\": \"positive\"}      8  \n",
       "3       {\"Mid caps\": \"positive\"}      7  \n",
       "4          {\"Market\": \"neutral\"}      8  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentfin = pd.read_csv('dataset/SEntFiN-v1.1.csv', encoding=\"latin-1\")\n",
    "sentfin.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    # Text normalization\n",
    "    contractions = {\n",
    "        \"isn't\": \"is not\",\n",
    "        \"aren't\": \"are not\",\n",
    "        \"wasn't\": \"was not\",\n",
    "        \"weren't\": \"were not\",\n",
    "        \"haven't\": \"have not\",\n",
    "        \"hasn't\": \"has not\",\n",
    "        \"hadn't\": \"had not\",\n",
    "        \"won't\": \"will not\",\n",
    "        \"wouldn't\": \"would not\",\n",
    "        \"don't\": \"do not\",\n",
    "        \"doesn't\": \"does not\",\n",
    "        \"didn't\": \"did not\",\n",
    "        \"can't\": \"can not\",\n",
    "        \"couldn't\": \"could not\",\n",
    "        \"shouldn't\": \"should not\",\n",
    "        \"mightn't\": \"might not\",\n",
    "        \"mustn't\": \"must not\",\n",
    "        \"I'm\": \"I am\",\n",
    "        \"You're\": \"you are\",\n",
    "        \"I've\": \"I have\",\n",
    "        \"UI\": \"user interface\",\n",
    "        \"UX\": \"user experience\",\n",
    "        \"u\": \"you\",\n",
    "    }\n",
    "    pattern = re.compile(r'\\b(' + '|'.join(contractions.keys()) + r')\\b')\n",
    "    expanded_text = pattern.sub(lambda match: contractions[match.group(0)], text)\n",
    "\n",
    "    normalized_text = uni.normalize('NFKD', expanded_text)\n",
    "    normalized_text = ''.join([c for c in normalized_text if not uni.combining(c)])\n",
    "\n",
    "    # emoji encoding\n",
    "    emojis = demoji.findall(text)\n",
    "\n",
    "    for emoji in emojis:\n",
    "        text = text.replace(emoji, \" \" + emojis[emoji].split(\":\")[0])\n",
    "\n",
    "    # text preprocessing\n",
    "    teks = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "    teks = teks.lower()\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    stop_words.update(['also', 'app', 'apps', 'application', 'applications', 'good'])\n",
    "    stop_words.remove('not')\n",
    "    tokens = word_tokenize(teks)\n",
    "    filtered_tokens = [word for word in tokens if word.isalnum() and not any(char.isdigit() for char in word) and word not in stop_words]\n",
    "    lemmatizer = nltk.WordNetLemmatizer()\n",
    "    lemma = [lemmatizer.lemmatize(word) for word in filtered_tokens]\n",
    "    clean_reviews = ' '.join(lemma)\n",
    "\n",
    "    return clean_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10753/10753 [00:05<00:00, 2007.03it/s]\n"
     ]
    }
   ],
   "source": [
    "sentfin['text'] = sentfin.Title.progress_apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S No.</th>\n",
       "      <th>Title</th>\n",
       "      <th>Decisions</th>\n",
       "      <th>Words</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>SpiceJet to issue 6.4 crore warrants to promoters</td>\n",
       "      <td>{'SpiceJet': 'neutral'}</td>\n",
       "      <td>8</td>\n",
       "      <td>spicejet issue crore warrant promoter</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>MMTC Q2 net loss at Rs 10.4 crore</td>\n",
       "      <td>{'MMTC': 'neutral'}</td>\n",
       "      <td>8</td>\n",
       "      <td>mmtc net loss r crore</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Mid-cap funds can deliver more, stay put: Experts</td>\n",
       "      <td>{'Mid-cap funds': 'positive'}</td>\n",
       "      <td>8</td>\n",
       "      <td>midcap fund deliver stay put expert</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Mid caps now turn into market darlings</td>\n",
       "      <td>{'Mid caps': 'positive'}</td>\n",
       "      <td>7</td>\n",
       "      <td>mid cap turn market darling</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Market seeing patience, if not conviction: Pra...</td>\n",
       "      <td>{'Market': 'neutral'}</td>\n",
       "      <td>8</td>\n",
       "      <td>market seeing patience not conviction prakash ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10748</th>\n",
       "      <td>10749</td>\n",
       "      <td>Negative on Chambal, Advanta: Mitesh Thacker</td>\n",
       "      <td>{'Chambal': 'negative', 'Advanta': 'negative'}</td>\n",
       "      <td>6</td>\n",
       "      <td>negative chambal advanta mitesh thacker</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10749</th>\n",
       "      <td>10750</td>\n",
       "      <td>Small, Mid-cap stocks may emerge outperformers</td>\n",
       "      <td>{'Small': 'positive', 'Mid-cap stocks': 'posit...</td>\n",
       "      <td>6</td>\n",
       "      <td>small midcap stock may emerge outperformers</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10750</th>\n",
       "      <td>10751</td>\n",
       "      <td>Rupee slips against US dollar</td>\n",
       "      <td>{'Rupee': 'negative', 'US dollar': 'neutral'}</td>\n",
       "      <td>5</td>\n",
       "      <td>rupee slip u dollar</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10751</th>\n",
       "      <td>10752</td>\n",
       "      <td>Rupee weak against US dollar</td>\n",
       "      <td>{'Rupee': 'negative', 'US dollar': 'neutral'}</td>\n",
       "      <td>5</td>\n",
       "      <td>rupee weak u dollar</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10752</th>\n",
       "      <td>10753</td>\n",
       "      <td>Australia shares flat; energy drags</td>\n",
       "      <td>{'Australia shares': 'neutral', 'energy': 'neu...</td>\n",
       "      <td>5</td>\n",
       "      <td>australia share flat energy drag</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10753 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       S No.                                              Title  \\\n",
       "0          1  SpiceJet to issue 6.4 crore warrants to promoters   \n",
       "1          2                  MMTC Q2 net loss at Rs 10.4 crore   \n",
       "2          3  Mid-cap funds can deliver more, stay put: Experts   \n",
       "3          4             Mid caps now turn into market darlings   \n",
       "4          5  Market seeing patience, if not conviction: Pra...   \n",
       "...      ...                                                ...   \n",
       "10748  10749       Negative on Chambal, Advanta: Mitesh Thacker   \n",
       "10749  10750     Small, Mid-cap stocks may emerge outperformers   \n",
       "10750  10751                      Rupee slips against US dollar   \n",
       "10751  10752                       Rupee weak against US dollar   \n",
       "10752  10753                Australia shares flat; energy drags   \n",
       "\n",
       "                                               Decisions  Words  \\\n",
       "0                                {'SpiceJet': 'neutral'}      8   \n",
       "1                                    {'MMTC': 'neutral'}      8   \n",
       "2                          {'Mid-cap funds': 'positive'}      8   \n",
       "3                               {'Mid caps': 'positive'}      7   \n",
       "4                                  {'Market': 'neutral'}      8   \n",
       "...                                                  ...    ...   \n",
       "10748     {'Chambal': 'negative', 'Advanta': 'negative'}      6   \n",
       "10749  {'Small': 'positive', 'Mid-cap stocks': 'posit...      6   \n",
       "10750      {'Rupee': 'negative', 'US dollar': 'neutral'}      5   \n",
       "10751      {'Rupee': 'negative', 'US dollar': 'neutral'}      5   \n",
       "10752  {'Australia shares': 'neutral', 'energy': 'neu...      5   \n",
       "\n",
       "                                                    text  label  \n",
       "0                  spicejet issue crore warrant promoter      1  \n",
       "1                                  mmtc net loss r crore      1  \n",
       "2                    midcap fund deliver stay put expert      2  \n",
       "3                            mid cap turn market darling      2  \n",
       "4      market seeing patience not conviction prakash ...      1  \n",
       "...                                                  ...    ...  \n",
       "10748            negative chambal advanta mitesh thacker      0  \n",
       "10749        small midcap stock may emerge outperformers      2  \n",
       "10750                                rupee slip u dollar      0  \n",
       "10751                                rupee weak u dollar      0  \n",
       "10752                   australia share flat energy drag      1  \n",
       "\n",
       "[10753 rows x 6 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ast\n",
    "# Mengonversi string JSON ke dictionary\n",
    "sentfin['Decisions'] = sentfin['Decisions'].apply(ast.literal_eval)\n",
    "# Ekstrak teks dan label\n",
    "sentfin['label'] = sentfin['Decisions'].apply(lambda x: list(x.values())[0])\n",
    "# Encode label\n",
    "le = LabelEncoder()\n",
    "sentfin['label'] = le.fit_transform(sentfin['label'])\n",
    "sentfin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spicejet issue crore warrant promoter</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mmtc net loss r crore</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>midcap fund deliver stay put expert</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mid cap turn market darling</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>market seeing patience not conviction prakash ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10748</th>\n",
       "      <td>negative chambal advanta mitesh thacker</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10749</th>\n",
       "      <td>small midcap stock may emerge outperformers</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10750</th>\n",
       "      <td>rupee slip u dollar</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10751</th>\n",
       "      <td>rupee weak u dollar</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10752</th>\n",
       "      <td>australia share flat energy drag</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10753 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label\n",
       "0                  spicejet issue crore warrant promoter      1\n",
       "1                                  mmtc net loss r crore      1\n",
       "2                    midcap fund deliver stay put expert      2\n",
       "3                            mid cap turn market darling      2\n",
       "4      market seeing patience not conviction prakash ...      1\n",
       "...                                                  ...    ...\n",
       "10748            negative chambal advanta mitesh thacker      0\n",
       "10749        small midcap stock may emerge outperformers      2\n",
       "10750                                rupee slip u dollar      0\n",
       "10751                                rupee weak u dollar      0\n",
       "10752                   australia share flat energy drag      1\n",
       "\n",
       "[10753 rows x 2 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = sentfin[['text', 'label']]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "is_cuda = torch.cuda.is_available()\n",
    "\n",
    "# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
    "if is_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU not available, CPU used\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting to train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of train data is (8064,)\n",
      "shape of test data is (2689,)\n"
     ]
    }
   ],
   "source": [
    "X,y = df['text'].values,df['label'].values\n",
    "x_train,x_test,y_train,y_test = train_test_split(X,y,stratify=y)\n",
    "print(f'shape of train data is {x_train.shape}')\n",
    "print(f'shape of test data is {x_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysing sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    3127\n",
       "1    2583\n",
       "0    2354\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(y_train).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dd = pd.Series(y_train).value_counts()\n",
    "sns.barplot(x=np.array(['0','1','2']),y=dd.values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tockenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_string(s):\n",
    "    # Remove all non-word characters (everything except numbers and letters)\n",
    "    s = re.sub(r\"[^\\w\\s]\", '', s)\n",
    "    # Replace all runs of whitespaces with no space\n",
    "    s = re.sub(r\"\\s+\", '', s)\n",
    "    # replace digits with no space\n",
    "    s = re.sub(r\"\\d\", '', s)\n",
    "\n",
    "    return s\n",
    "\n",
    "def tockenize(x_train,y_train,x_val,y_val):\n",
    "    word_list = []\n",
    "\n",
    "    stop_words = set(stopwords.words('english')) \n",
    "    for sent in x_train:\n",
    "        for word in sent.lower().split():\n",
    "            word = preprocess_string(word)\n",
    "            if word not in stop_words and word != '':\n",
    "                word_list.append(word)\n",
    "  \n",
    "    corpus = Counter(word_list)\n",
    "    # sorting on the basis of most common words\n",
    "    corpus_ = sorted(corpus,key=corpus.get,reverse=True)[:1000]\n",
    "    # creating a dict\n",
    "    onehot_dict = {w:i+1 for i,w in enumerate(corpus_)}\n",
    "    \n",
    "    # tockenize\n",
    "    final_list_train,final_list_test = [],[]\n",
    "    for sent in x_train:\n",
    "            final_list_train.append([onehot_dict[preprocess_string(word)] for word in sent.lower().split() \n",
    "                                     if preprocess_string(word) in onehot_dict.keys()])\n",
    "    for sent in x_val:\n",
    "            final_list_test.append([onehot_dict[preprocess_string(word)] for word in sent.lower().split() \n",
    "                                    if preprocess_string(word) in onehot_dict.keys()])\n",
    "            \n",
    "    encoded_train = [1 if label =='positive' else 0 for label in y_train]  \n",
    "    encoded_test = [1 if label =='positive' else 0 for label in y_val] \n",
    "    return np.array(final_list_train), np.array(encoded_train),np.array(final_list_test), np.array(encoded_test),onehot_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (8064,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m x_train,y_train,x_test,y_test,vocab \u001b[38;5;241m=\u001b[39m \u001b[43mtockenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[34], line 38\u001b[0m, in \u001b[0;36mtockenize\u001b[0;34m(x_train, y_train, x_val, y_val)\u001b[0m\n\u001b[1;32m     36\u001b[0m encoded_train \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m label \u001b[38;5;241m==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpositive\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m label \u001b[38;5;129;01min\u001b[39;00m y_train]  \n\u001b[1;32m     37\u001b[0m encoded_test \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m label \u001b[38;5;241m==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpositive\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m label \u001b[38;5;129;01min\u001b[39;00m y_val] \n\u001b[0;32m---> 38\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(final_list_train), np\u001b[38;5;241m.\u001b[39marray(encoded_train),np\u001b[38;5;241m.\u001b[39marray(final_list_test), np\u001b[38;5;241m.\u001b[39marray(encoded_test),onehot_dict\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (8064,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "x_train,y_train,x_test,y_test,vocab = tockenize(x_train,y_train,x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contoh definisi model RNN sederhana\n",
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNNModel, self).__init__()\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out, _ = self.rnn(x)\n",
    "        out = self.fc(out[:, -1, :])  # Mengambil output dari step terakhir\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 100  # Misalnya, ukuran vektor kata setelah tokenisasi\n",
    "hidden_size = 128\n",
    "output_size = 3  # Misalnya, 3 kelas sentimen (negatif, netral, positif)\n",
    "\n",
    "model = RNNModel(input_size, hidden_size, output_size)\n",
    "\n",
    "# Definisikan loss dan optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7b1e64e2f110>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[72], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[0;32m----> 6\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m  \u001b[38;5;66;03m# Ambil judul atau fitur yang relevan\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     labels \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m]  \u001b[38;5;66;03m# Ambil label sentimen yang telah diencode\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;66;03m# Lakukan tokenisasi dan encoding di sini jika diperlukan\u001b[39;00m\n\u001b[1;32m     10\u001b[0m     \n\u001b[1;32m     11\u001b[0m     \u001b[38;5;66;03m# Contoh: Ubah input menjadi tensor PyTorch\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for batch in train_loader:\n",
    "        inputs = batch['text']  # Ambil judul atau fitur yang relevan\n",
    "        labels = batch['label']  # Ambil label sentimen yang telah diencode\n",
    "        \n",
    "        # Lakukan tokenisasi dan encoding di sini jika diperlukan\n",
    "        \n",
    "        # Contoh: Ubah input menjadi tensor PyTorch\n",
    "        inputs_tensor = torch.Tensor(inputs)  # Sesuaikan dengan tokenisasi Anda\n",
    "        labels_tensor = torch.Tensor(labels)  # Sesuaikan dengan encoding Anda\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(inputs_tensor)\n",
    "        \n",
    "        # Hitung loss\n",
    "        loss = criterion(outputs, labels_tensor)\n",
    "        \n",
    "        # Backward pass dan optimasi\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # Evaluasi model di setiap epoch\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            inputs = batch['title']\n",
    "            labels = batch['decision']\n",
    "            \n",
    "            # Lakukan tokenisasi dan encoding di sini jika diperlukan\n",
    "            \n",
    "            inputs_tensor = torch.Tensor(inputs)  # Sesuaikan dengan tokenisasi Anda\n",
    "            labels_tensor = torch.Tensor(labels)  # Sesuaikan dengan encoding Anda\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(inputs_tensor)\n",
    "            \n",
    "            # Hitung loss\n",
    "            loss = criterion(outputs, labels_tensor)\n",
    "            val_loss += loss.item()\n",
    "            \n",
    "            # Hitung akurasi\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels_tensor.size(0)\n",
    "            correct += (predicted == labels_tensor).sum().item()\n",
    "    \n",
    "    epoch_val_loss = val_loss / len(val_loader)\n",
    "    epoch_accuracy = correct / total\n",
    "    \n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {loss.item():.4f}, Val Loss: {epoch_val_loss:.4f}, Val Accuracy: {epoch_accuracy:.2f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
